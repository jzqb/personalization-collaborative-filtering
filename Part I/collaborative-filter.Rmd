---
title: "IEOR 4571: Building a Collaborative Filter"
output: html_notebook
---

```{r}
library(reshape2)
library(lsa)
library(Hmisc)
```
Let's begin by importing the libraries here. We will be using the libraries mentioned above to perform intermediary calculations.

```{r}
ratings <- read.csv('../data/jester-data-1.csv', header = FALSE)
ratings <- ratings[-1]
names(ratings) <- paste('i_',c(1:100), sep = "")
ratings[ratings ==99] <- NA
sparsity <- sum(is.na(ratings))/dim(ratings)[1]/dim(ratings)[2]
```
After reading the data: The sparsity in the data set is `r paste(round(sparsity*100,2),"%", sep = "")`

### Item Based CF Models
```{r}
item_similarity_cosine <- function(ratings){
  item_ratings <- ratings
  item_ratings_centered <- as.data.frame(t(apply(t(item_ratings), 2, FUN = function(x){x- mean(x, na.rm = T)})))
  cos_ratings <- item_ratings_centered
  cos_ratings[is.na(cos_ratings)] <- 0
  cosine_item_sim <- cosine(as.matrix(cos_ratings))
  return(cosine_item_sim)
}

item_similarity_pearson <- function(ratings){
  item_ratings <- ratings
  pear_item_sim <- as.matrix(cor(item_ratings, use = 'pairwise.complete.obs'))
  return(pear_item_sim)
}

predict_rating_item_cf <- function(ratings, k=20, user_no, item_no, similarity = c('cosine', 'pearson')){
  user <- ratings[user_no,] 
  unrated <- names(user[,is.na(user)])
  rated <- names(user[,!is.na(user)])
  if(paste('i_',item_no, sep = "") %nin% unrated){
    return(ratings[user_no, item_no])
  }
  else{
    if(similarity == 'cosine'){use_sim = i_s_c}
    else{use_sim = i_s_p}
    sim_mov <- as.data.frame(use_sim[,item_no])
    sim_mov$item <- row.names(sim_mov)
    sim_mov <- sim_mov[order(-sim_mov$`use_sim[, item_no]`),]
    sim_mov <- sim_mov[sim_mov$item != paste('i_',item_no, sep = ""),]
    sim_mov <- sim_mov[1:k,]
    sim_mov <- sim_mov[sim_mov$item %in% rated,]
    um <- as.data.frame(t(user[,!is.na(user)]))
    um$item <- rownames(um)
    rate_insitu <- merge(sim_mov, um, by = 'item', all.x = T)
    names(rate_insitu) <- c('item', 'sim', 'rating')
    rate_insitu$rating <- as.numeric(as.character(rate_insitu$rating))
    return(sum(rate_insitu$sim*rate_insitu$rating)/sum(rate_insitu$sim))
  }
}
```
I need to write description of what functions are doing here.


### User Based CF Models
Because there are so many users, it is infeasible to directly call correlation functions in R due to limited RAM. Writing custom function to calcuated neccesary similarity measures.
```{r}
factorized <- function(x) {
  x <- as.integer(x)
  div <- seq_len(abs(x))
  factors <- div[x %% div == 0L]
  return(factors)
}
bigcor <- function(x, similarity = c('cosine', 'pearson'), verbose = TRUE, ...)
{
  library(ff, quietly = TRUE)
  NCOL <- ncol(x)
  nblocks = factorized(NCOL)[2]
  ## test if ncol(x) %% nblocks gives remainder 0
  if (NCOL %% nblocks != 0) stop("Choose different 'nblocks' so that ncol(x) %% nblocks = 0!")
  
  ## preallocate square matrix of dimension
  ## ncol(x) in 'ff' single format
  corMAT <- ff(vmode = "single", dim = c(NCOL, NCOL))
  
  ## split column numbers into 'nblocks' groups
  SPLIT <- split(1:NCOL, rep(1:nblocks, each = NCOL/nblocks))
  
  ## create all unique combinations of blocks
  COMBS <- expand.grid(1:length(SPLIT), 1:length(SPLIT))
  COMBS <- t(apply(COMBS, 1, sort))
  COMBS <- unique(COMBS)
  
  ## iterate through each block combination, calculate correlation matrix
  ## between blocks and store them in the preallocated matrix on both
  ## symmetric sides of the diagonal
  for (i in 1:nrow(COMBS)) {
    COMB <- COMBS[i, ]
    G1 <- SPLIT[[COMB[1]]]
    G2 <- SPLIT[[COMB[2]]]
    if (verbose) cat("Block", COMB[1], "with Block", COMB[2], "\n")
    flush.console()
    COR <- cor(MAT[, G1], MAT[, G2], use = 'pairwise.complete.obs',...)
    corMAT[G1, G2] <- COR
    corMAT[G2, G1] <- t(COR)
    COR <- NULL
  }
  
  gc()
  return(corMAT)
}
```
```{r}
user_similarity_pearson <- function(ratings){
  MAT <- t(ratings)
  pear_user_sim <- bigcor(MAT)
  return(pear_user_sim)
}
```


```{r}
# converting wide data to long format to sample and measure accuracy of the model
wide_to_long <- function(ratings){
  ratings <- cbind(user = paste('u_',row.names(ratings), sep = ""), ratings)
  molten <- melt(ratings, na.rm = T, id.vars = 'user')
  return(molten)
}

# split function to train the model and separate validation data
train_test_split <- function(ratings, train_proportion = 0.8){
  sample_size <- floor(train_proportion*nrow(ratings))
  train_ind <- sample(seq_len(nrow(ratings)), size = sample_size)
  train_data <- ratings[train_ind,]
  test_data <- ratings[-train_ind,]
  split_data <- list('train_data' = train_data, 'test_data' = test_data)
  return(split_data)
}
```
Writing these functions so that I can build pipelines of my own.

### Time to Call Some Functions
```{r}
molten_data <- wide_to_long(ratings)
set.seed(666)
molten_data_split <- train_test_split(molten_data)
train_data <- molten_data_split$train_data
feed_data <- dcast(train_data, formula = user~variable, fun.aggregate = mean, fill = NA_real_)
feed_data$user <- as.numeric(gsub( 'u_', '', feed_data$user))
feed_data <- feed_data[order(feed_data$user),]
feed_data <- feed_data[-1]
rownames(feed_data) <- c(1:nrow(feed_data))
i_s_c <- item_similarity_cosine(feed_data)
i_s_p <- item_similarity_pearson(feed_data)

test_data <- molten_data_split$test_data
data_avg_rating <- mean(molten_data$value)
baseline_mae <- sum(abs(test_data$value - data_avg_rating))/nrow(test_data)
test_users <- as.numeric(gsub('u_', '', test_data$user))
test_items <- as.numeric(gsub('i_', '', test_data$variable))

test_data$prediction <- 0
for(test_case in 1:1000){
  test_user <- as.numeric(gsub('u_', '',test_data[test_case,1]))
  test_item <- as.numeric(gsub('i_', '',test_data[test_case,2]))
  test_data[test_case, 4] <- predict_rating_item_cf(feed_data, k = 20, test_user, test_item, similarity = 'cosine')
}
insitu <- test_data[1:100,]
cos_mae <- sum(abs(insitu$value - insitu$prediction))/nrow(insitu)


test_data$prediction <- 0
for(test_case in 1:1000){
  test_user <- as.numeric(gsub('u_', '',test_data[test_case,1]))
  test_item <- as.numeric(gsub('i_', '',test_data[test_case,2]))
  test_data[test_case, 4] <- predict_rating_item_cf(feed_data, k = 20, test_user, test_item, similarity = 'pearson')
}
insitu <- test_data[1:100,]
pear_mae <- sum(abs(insitu$value - insitu$prediction))/nrow(insitu)
```
Just ran a basic test case on the cf model, the baseline_mae for the data is `r round(baseline_mae,2)` if one were to predict the ratings with the average rating in the data.
However, currently on the first 1000 test cases, the cosine_mae is `r round(cos_mae,2)` while the pearson_mae is `r round(pear_mae,2)`

