getwd()
write.csv(mtcars, 'mtcars.csv', row.names=F)
knitr::opts_chunk$set(echo = TRUE)
df1 <- mtcars
head(df1)
getwd()
install.packages('prettydoc')
getwd()
ls
ls()
list.files()
library(data.table)
df1 <- as.data.table(mtcars)
View(df1)
?setorderv
setorderv(df1, 'mpg', 1)
View(df1)
dat <- setorderv(x = df1, cols = c("mpg", "cyl"), order = c(1, 1))
baseline <- dat[, .SD[1], .SDcols = clinical.factors,
by = "mpg"]
baseline <- dat[, .SD[1], .SDcols = c('disp', 'hp'),
by = "mpg"]
View(baseline)
## @knitr packages_and_libraries
library(knitr, quietly = T)
library(reshape2, quietly = T)
library(lsa, quietly = T)
library(Hmisc, quietly = T)
library(plotly, quietly = T)
library(DT, quietly = T)
library(recommenderlab, quietly = T)
library(XML, quietly = T)
library(stringr, quietly = T)
library(kableExtra, quietly = T)
setwd("~/Desktop/drive/dsi/fall-17/personalization/personalization-collaborative-filtering/Part I")
## @knitr aux_funct_wide_to_long
wide_to_long <- function(ratings){
ratings <- cbind(user = paste('u_',row.names(ratings), sep = ""), ratings)
molten <- melt(ratings, na.rm = T, id.vars = 'user')
return(molten)
}
## @knitr aux_funct_train_test_split
train_test_split <- function(ratings, train_proportion = 0.8){
sample_size <- floor(train_proportion*nrow(ratings))
train_ind <- sample(seq_len(nrow(ratings)), size = sample_size)
train_data <- ratings[train_ind,]
test_data <- ratings[-train_ind,]
split_data <- list('train_data' = train_data, 'test_data' = test_data)
return(split_data)
}
ratings <- read.csv('../data/jester-data-1.csv', header = FALSE)
ratings <- ratings[-1]
names(ratings) <- paste('i_',c(1:100), sep = "")
ratings[ratings ==99] <- NA
kable(ratings[1:4,1:10], "html", caption = "Sample Ratings of First 4 users and 10 jokes: User x Item") %>%
kable_styling(bootstrap_options = "striped", full_width = F)
sparsity <- sum(is.na(ratings))/dim(ratings)[1]/dim(ratings)[2]
paste('The sparsity in the dataset is ', round(sparsity*100,2), "%", sep = "")
molten_data <- wide_to_long(ratings)
fit_density <- density(molten_data$value)
p0 <- qplot(molten_data$value, geom = 'blank') +
geom_line(aes(y = ..density.., colour = 'Empirical'), stat = 'density') +
stat_function(fun = dnorm, aes(colour = 'Normal')) +
geom_histogram(aes(y = ..density..), alpha = 0.4) +
scale_colour_manual(name = 'Density', values = c('red', 'blue')) +
theme(legend.position = c(0.85, 0.85))
print(p0)
ggplot(molten_data$value, aes(x)) +
geom_histogram(aes(y = ..density..)) +
stat_function(fun = dnorm,
args = list(mean = mean(df$x), sd = sd(df$x)),
lwd = 2,
col = 'red')
ggplot(molten_data[,value], aes(x)) +
geom_histogram(aes(y = ..density..)) +
stat_function(fun = dnorm,
args = list(mean = mean(df$x), sd = sd(df$x)),
lwd = 2,
col = 'red')
ggplot(molten_data[,'value'], aes(x)) +
geom_histogram(aes(y = ..density..)) +
stat_function(fun = dnorm,
args = list(mean = mean(df$x), sd = sd(df$x)),
lwd = 2,
col = 'red')
qplot(molten_data$value,
geom="histogram",
binwidth = 0.5,
main = "Histogram for Ratings",
xlab = "Age",
fill=I("blue"),
col=I("red"),
alpha=I(.2),
xlim=c(-10,10))
rat_per_user_more <- sum(molten_data$value>=0)/length(unique(molten_data$user[molten_data$value>=0]))
rat_per_user_less <- sum(molten_data$value<0)/length(unique(molten_data$user[molten_data$value<0]))
avg_rat_per_user_more <- mean(molten_data$value[molten_data$value>=0])
avg_rat_per_user_less <- mean(molten_data$value[molten_data$value<0])
paste('On an average, a user rated ', round(rat_per_user_more,0), ' jokes more than 0 with an average rating of ', round(avg_rat_per_user_more,2), '. While it was ', round(rat_per_user_less,0), ' jokes and ',round(avg_rat_per_user_less,2), ' for less than 0 respectively!', sep = "")
all_files <- list.files('../data/jokes')
joke_numbers <- vector()
joke_text <- vector()
regexp <- "[[:digit:]]+"
for(filer in all_files){
joke_serial <- as.numeric(str_extract(filer, regexp))
doc_html <- htmlTreeParse(paste('../data/jokes/', filer,sep = ""), useInternal = TRUE)
doc_text <- unlist(xpathApply(doc_html, '//font', xmlValue))
doc_text <- gsub('\\n', ' ', doc_text)
doc_text <- paste(doc_text, collapse = " ")
joke_numbers <- append(joke_numbers, joke_serial)
joke_text <- append(joke_text, doc_text)
}
joke_text <- data.frame(joke_no = joke_numbers, joke_text = joke_text)
ratings_sparse <- as(as.matrix(ratings), 'realRatingMatrix') # helps to reduce memory for sparse matrix storage
jokes_rated <- colCounts(ratings_sparse)
jokes_avg_rating <- round(colMeans(ratings_sparse),3)
table_rated <- data.frame(joke_number = names(jokes_rated), jokes_rated, jokes_avg_rating)
# seeing the top3 and bottom3 rated jokes
top3_rated_jokes <- head(table_rated[order(-table_rated$jokes_rated),],3)
bottom3_rated_jokes <- head(table_rated[order(table_rated$jokes_rated),],3)
# best and worst jokes based on ratings
best3_jokes <- head(table_rated[order(-table_rated$jokes_avg_rating),],3)
worst3_jokes <- head(table_rated[order(table_rated$jokes_avg_rating),],3)
f <- list(
family = "Courier New, monospace",
size = 18,
color = "#7f7f7f"
)
x <- list(
title = "ratings",
titlefont = f
)
y1 <- list(
title = "frequency",
titlefont = f
)
y2 <- list(
title = "density",
titlefont = f,
overlaying = "y",
side = "right"
)
fit_density_avg <- density(jokes_avg_rating)
histo_ratings_avg <- plot_ly(x = jokes_avg_rating, type = "histogram", name = "Histogram") %>%
add_trace(x = fit_density_avg$x, y = fit_density_avg$y, type = "scatter", mode = "lines", fill = "tozeroy", yaxis = "y2", name = "Density") %>%
layout(title = 'Distribution of Average Ratings', xaxis = x, yaxis = y1, yaxis2 = y2)
histo_ratings_avg
length(fit_density)
length(fit_density_avg)
length(jokes_avg_rating)
sample_heat_data <- as.matrix(ratings)
heat_map <- plot_ly(
x = names(ratings), y = rownames(ratings),
z = sample_heat_data, type = "heatmap",
colorscale = "Greys"
) %>%
layout(title = 'Ratings Matrix Visualization', xaxis = x <- list(title = "items [jokes]", titlefont = f), yaxis = list(title = "users", titlefont = f))
heat_map
variable
names(sample_heat_data)
class(ratings)
names(ratings)
p <- ggplot(ratings, aes(items, users)) + geom_tile(aes(fill = rescale), colour = "white") + scale_fill_gradient(low = "white", high = "steelblue")
p
library(ggplot2)
p <- ggplot(ratings, aes(items, users)) + geom_tile(aes(fill = rescale), colour = "white") + scale_fill_gradient(low = "white", high = "steelblue")
p
df.team_data <- expand.grid(teams = c("Team A", "Team B", "Team C", "Team D")
,metrics = c("Metric 1", "Metric 2", "Metric 3", "Metric 4", "Metric 5")
)
df.team_data$performance <- rnorm(nrow(df.team_data))
View(df)
head(df.team_data)
names(molten_data)
p <- ggplot(molten_data, aes(variable, user)) + geom_tile(aes(fill = value), colour = "white") + scale_fill_gradient(low = "white", high = "steelblue")
p
print(p)
ggplot(data = molten_data, aes(x = variable, y = user)) +  geom_tile(aes(fill = value)
rm(list = ls())
ratings <- read.csv('../data/jester-data-1.csv', header = FALSE)
ratings <- ratings[-1]
names(ratings) <- paste('i_',c(1:100), sep = "")
ratings[ratings ==99] <- NA
recommender_models <- recommenderRegistry$get_entries(dataType = "realRatingMatrix")
recommender_models$UBCF_realRatingMatrix$parameters
ubcf_cosine <- Recommender(data = training_sparse, method = "UBCF")
ubcf_cosine
model_details <- getModel(ubcf_cosine)
model_details$description
## @knitr aux_funct_wide_to_long
wide_to_long <- function(ratings){
ratings <- cbind(user = paste('u_',row.names(ratings), sep = ""), ratings)
molten <- melt(ratings, na.rm = T, id.vars = 'user')
return(molten)
}
## @knitr aux_funct_train_test_split
train_test_split <- function(ratings, train_proportion = 0.8){
sample_size <- floor(train_proportion*nrow(ratings))
train_ind <- sample(seq_len(nrow(ratings)), size = sample_size)
train_data <- ratings[train_ind,]
test_data <- ratings[-train_ind,]
split_data <- list('train_data' = train_data, 'test_data' = test_data)
return(split_data)
}
set.seed(666)
train_proportion = 0.8
molten_data <- wide_to_long(ratings) # remomve this in final report
molten_data_split <- train_test_split(molten_data, train_proportion = train_proportion)
train_data <- molten_data_split$train_data
feed_data <- dcast(train_data, formula = user~variable, fun.aggregate = mean, fill = NA_real_)
feed_data$user <- as.numeric(gsub( 'u_', '', feed_data$user))
feed_data <- feed_data[order(feed_data$user),]
feed_data <- feed_data[-1]
rownames(feed_data) <- c(1:nrow(feed_data))
training_sparse <- as(as.matrix(feed_data), 'realRatingMatrix')
test_data <- molten_data_split$test_data
ubcf_cosine <- Recommender(data = training_sparse, method = "UBCF")
ubcf_cosine
model_details <- getModel(ubcf_cosine)
model_details$description
test_data <- molten_data_split$test_data
predicted_ratings <- predict(ubcf_cosine, training_sparse, type = 'ratings')
predicted_ratings <- as(predicted_ratings, 'data.frame')
predicted_ratings$user <- paste('u_', as.character(predicted_ratings$user), sep = "")
predicted_ratings$item <- as.character(predicted_ratings$item)
test_data$user <- as.character(test_data$user)
test_data$variable <- as.character(test_data$variable)
test_data <- merge(test_data, predicted_ratings, by.x = c('user', 'variable'), by.y = c('user','item'), all.x = TRUE)
cosine_ubcf_mae <- mean(abs(test_data$value-test_data$rating), na.rm = TRUE)
cosine_ubcf_mae
top_n_predicted_ubcf <- predict(object = ubcf_cosine, ratings_sparse, n = 5)
first_user_reco <- top_n_predicted_ubcf@items[[1]]
jokes_user_1 <- top_n_predicted_ubcf@itemLabels[first_user_reco]
recc_matrix <- sapply(top_n_predicted_ubcf@items, function(x){
colnames(ratings_sparse)[x]
})
recc_data <- do.call(rbind, lapply(recc_matrix, data.frame, stringsAsFactors=FALSE))
names(recc_data) <- 'item_recommended'
number_of_items <- factor(table(recc_data$item_recommended))
top_n_predicted_ubcf <- predict(object = ubcf_cosine, ratings_sparse, n = 5)
ratings_sparse <- as(as.matrix(ratings), 'realRatingMatrix')
top_n_predicted_ubcf <- predict(object = ubcf_cosine, ratings_sparse, n = 5)
first_user_reco <- top_n_predicted_ubcf@items[[1]]
jokes_user_1 <- top_n_predicted_ubcf@itemLabels[first_user_reco]
recc_matrix <- sapply(top_n_predicted_ubcf@items, function(x){
colnames(ratings_sparse)[x]
})
recc_data <- do.call(rbind, lapply(recc_matrix, data.frame, stringsAsFactors=FALSE))
names(recc_data) <- 'item_recommended'
number_of_items <- factor(table(recc_data$item_recommended))
save.image('ubcf_cf.RData')
jj
rm(list = ls)
rm(list = ls())
load('ubcf_cf.RData')
cosine_ubcf_mae
item_similarity_cosine <- function(ratings){
item_ratings <- ratings
item_ratings_centered <- as.data.frame(t(apply(t(item_ratings), 2, FUN = function(x){x- mean(x, na.rm = T)})))
cos_ratings <- item_ratings_centered
cos_ratings[is.na(cos_ratings)] <- 0
cosine_item_sim <- cosine(as.matrix(cos_ratings))
return(cosine_item_sim)
}
item_similarity_pearson <- function(ratings){
item_ratings <- ratings
pear_item_sim <- as.matrix(cor(item_ratings, use = 'pairwise.complete.obs'))
return(pear_item_sim)
}
predict_rating_item_cf <- function(ratings, k=20, user_no, item_no, similarity = c('cosine', 'pearson')){
user <- ratings[user_no,]
unrated <- names(user[,is.na(user)])
rated <- names(user[,!is.na(user)])
if(paste('i_',item_no, sep = "") %nin% unrated){
return(ratings[user_no, item_no])
}
else{
if(similarity == 'cosine'){use_sim = i_s_c}
else{use_sim = i_s_p}
sim_mov <- as.data.frame(use_sim[,item_no])
sim_mov$item <- row.names(sim_mov)
sim_mov <- sim_mov[order(-sim_mov$`use_sim[, item_no]`),]
sim_mov <- sim_mov[sim_mov$item != paste('i_',item_no, sep = ""),]
sim_mov <- sim_mov[1:k,]
sim_mov <- sim_mov[sim_mov$item %in% rated,]
um <- as.data.frame(t(user[,!is.na(user)]))
um$item <- rownames(um)
rate_insitu <- merge(sim_mov, um, by = 'item', all.x = T)
names(rate_insitu) <- c('item', 'sim', 'rating')
rate_insitu$rating <- as.numeric(as.character(rate_insitu$rating))
return(sum(rate_insitu$sim*rate_insitu$rating)/sum(rate_insitu$sim))
}
}
i_s_c <- item_similarity_cosine(feed_data)
library(lsa, quietly = T)
i_s_c <- item_similarity_cosine(feed_data)
i_s_p <- item_similarity_pearson(feed_data)
test_data <- molten_data_split$test_data
set.seed(666)
train_proportion = 0.8
molten_data <- wide_to_long(ratings) # remomve this in final report
molten_data_split <- train_test_split(molten_data, train_proportion = train_proportion)
train_data <- molten_data_split$train_data
feed_data <- dcast(train_data, formula = user~variable, fun.aggregate = mean, fill = NA_real_)
feed_data$user <- as.numeric(gsub( 'u_', '', feed_data$user))
feed_data <- feed_data[order(feed_data$user),]
feed_data <- feed_data[-1]
rownames(feed_data) <- c(1:nrow(feed_data))
training_sparse <- as(as.matrix(feed_data), 'realRatingMatrix')
ibcf_pearson <- Recommender(data = training_sparse, method = "IBCF", parameter = list(k = 30, method = 'pearson'))
ibcf_pearson
model_details <- getModel(ibcf_pearson)
model_details$description
set.seed(666)
train_proportion = 0.8
molten_data <- wide_to_long(ratings) # remomve this in final report
## @knitr packages_and_libraries
library(knitr, quietly = T)
library(reshape2, quietly = T)
library(lsa, quietly = T)
library(Hmisc, quietly = T)
library(plotly, quietly = T)
library(DT, quietly = T)
library(recommenderlab, quietly = T)
library(XML, quietly = T)
library(stringr, quietly = T)
library(kableExtra, quietly = T)
library(lsa, quietly = T)
set.seed(666)
train_proportion = 0.8
molten_data <- wide_to_long(ratings) # remomve this in final report
molten_data_split <- train_test_split(molten_data, train_proportion = train_proportion)
train_data <- molten_data_split$train_data
feed_data <- dcast(train_data, formula = user~variable, fun.aggregate = mean, fill = NA_real_)
feed_data$user <- as.numeric(gsub( 'u_', '', feed_data$user))
feed_data <- feed_data[order(feed_data$user),]
feed_data <- feed_data[-1]
rownames(feed_data) <- c(1:nrow(feed_data))
training_sparse <- as(as.matrix(feed_data), 'realRatingMatrix')
ibcf_pearson <- Recommender(data = training_sparse, method = "IBCF", parameter = list(k = 30, method = 'pearson'))
ibcf_pearson
model_details <- getModel(ibcf_pearson)
model_details$description
test_data$prediction <- 0
for(test_case in 1:100000){
test_user <- as.numeric(gsub('u_', '',test_data[test_case,1]))
test_item <- as.numeric(gsub('i_', '',test_data[test_case,2]))
test_data[test_case, 4] <- predict_rating_item_cf(feed_data, k = 20, test_user, test_item, similarity = 'cosine')
}
test_data$prediction <- 0
for(test_case in 1:10000){
test_user <- as.numeric(gsub('u_', '',test_data[test_case,1]))
test_item <- as.numeric(gsub('i_', '',test_data[test_case,2]))
test_data[test_case, 4] <- predict_rating_item_cf(feed_data, k = 20, test_user, test_item, similarity = 'cosine')
}
insitu <- test_data[1:10000,]
cos_mae_ibcf_bf <- sum(abs(insitu$value - insitu$prediction), na.rm = T)/nrow(insitu)
cos_mae_ibcf_bf
test_data$prediction <- 0
for(test_case in 1:10000){
test_user <- as.numeric(gsub('u_', '',test_data[test_case,1]))
test_item <- as.numeric(gsub('i_', '',test_data[test_case,2]))
test_data[test_case, 4] <- predict_rating_item_cf(feed_data, k = 20, test_user, test_item, similarity = 'pearson')
}
insitu <- test_data[1:10000,]
pear_mae <- sum(abs(insitu$value - insitu$prediction))/nrow(insitu)
save.image('ubcf_cf.RData')
pear_mae
ubcf_cosine <- Recommender(data = training_sparse, method = "UBCF")
ubcf_cosine
model_details <- getModel(ubcf_cosine)
model_details$description
install.packages('arulesviz')
install.packages('arulesViz')
